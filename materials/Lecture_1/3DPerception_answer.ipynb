{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5731f38-a7bc-4d63-b149-8a11767eb4c8",
   "metadata": {},
   "source": [
    "# 3D Perception Tutorial\n",
    "\n",
    "We will explore the (1)3D object classification and the (2)instance-level semantic segmentation of indoor scenes. To get to theses goals, this tutorial will guide you through the basic concepts and practical applications of WarpConvNet for point cloud procesing, sparse voxel convolutions, and 3D attention mechanisms.\n",
    "\n",
    "## Table of Contents\n",
    "1. Basic Concepts\n",
    "2. PointCloud Representation\n",
    "3. Voxel Representation\n",
    "4. SparseConvNet\n",
    "5. Exercise 1: 3D Point Cloud Semantic Segmentation with SparseConvNet\n",
    "6. Exercise 2: 3D Point Cloud Semantic Segmentation with PointTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959f3b53-dcb3-4a48-bf83-ea6f2e95201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from typing import Optional, Tuple, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b3faf-9aa4-4f4d-94a1-b4ebf560960c",
   "metadata": {},
   "source": [
    "## PointCloud Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9570bb15-a210-443e-8958-279a4e1edfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "def visualize_point_cloud(points, colors=None, title=\"Point Cloud\", \n",
    "                         point_size=2, colorscale='Viridis', show_axis=True):\n",
    "    \"\"\"\n",
    "    Interactive 3D point cloud visualization using Plotly\n",
    "    \n",
    "    Args:\n",
    "        points: numpy array of shape (N, 3)\n",
    "        colors: optional colors for points (can be RGB values or scalar values)\n",
    "        title: title for the plot\n",
    "        point_size: size of points in the visualization\n",
    "        colorscale: Plotly colorscale name\n",
    "        show_axis: whether to show axis labels\n",
    "    \"\"\"\n",
    "    if isinstance(points, torch.Tensor):\n",
    "        points = points.cpu().numpy()\n",
    "    \n",
    "    if colors is None:\n",
    "        # Color by height (z-coordinate)\n",
    "        colors = points[:, 2]\n",
    "    elif isinstance(colors, torch.Tensor):\n",
    "        colors = colors.cpu().numpy()\n",
    "    \n",
    "    # Create 3D scatter plot\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=points[:, 0],\n",
    "        y=points[:, 1],\n",
    "        z=points[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=point_size,\n",
    "            color=colors if len(colors.shape) == 1 else colors[:, 0],  # Use first channel if RGB\n",
    "            colorscale=colorscale,\n",
    "            showscale=True,\n",
    "            colorbar=dict(\n",
    "                title=\"Value\",\n",
    "                thickness=20,\n",
    "                len=0.7\n",
    "            )\n",
    "        ),\n",
    "        text=[f\"Point {i}<br>x: {x:.3f}<br>y: {y:.3f}<br>z: {z:.3f}\" \n",
    "              for i, (x, y, z) in enumerate(points[:min(1000, len(points))])],  # Limit hover text for performance\n",
    "        hovertemplate='%{text}<extra></extra>'\n",
    "    )])\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=title,\n",
    "            x=0.5,\n",
    "            xanchor='center'\n",
    "        ),\n",
    "        scene=dict(\n",
    "            xaxis=dict(title='X' if show_axis else '', showgrid=True, gridwidth=1),\n",
    "            yaxis=dict(title='Y' if show_axis else '', showgrid=True, gridwidth=1),\n",
    "            zaxis=dict(title='Z' if show_axis else '', showgrid=True, gridwidth=1),\n",
    "            camera=dict(\n",
    "                eye=dict(x=1.5, y=1.5, z=1.5)\n",
    "            ),\n",
    "            aspectmode='auto'\n",
    "        ),\n",
    "        width=900,\n",
    "        height=700,\n",
    "        margin=dict(r=20, b=10, l=10, t=40),\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def visualize_multiple_point_clouds(point_clouds_dict, title=\"Multiple Point Clouds\"):\n",
    "    \"\"\"\n",
    "    Visualize multiple point clouds in the same plot with different colors\n",
    "    \n",
    "    Args:\n",
    "        point_clouds_dict: Dictionary with {name: points_array} pairs\n",
    "        title: overall title for the plot\n",
    "    \"\"\"\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Color palette for different point clouds\n",
    "    colors = px.colors.qualitative.Set1\n",
    "    \n",
    "    for idx, (name, points) in enumerate(point_clouds_dict.items()):\n",
    "        if isinstance(points, torch.Tensor):\n",
    "            points = points.cpu().numpy()\n",
    "        \n",
    "        color = colors[idx % len(colors)]\n",
    "        \n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=points[:, 0],\n",
    "            y=points[:, 1],\n",
    "            z=points[:, 2],\n",
    "            mode='markers',\n",
    "            name=name,\n",
    "            marker=dict(\n",
    "                size=3,\n",
    "                color=color,\n",
    "                opacity=0.8\n",
    "            ),\n",
    "            text=[f\"{name} - Point {i}\" for i in range(min(100, len(points)))],\n",
    "            hovertemplate='%{text}<br>x: %{x:.3f}<br>y: %{y:.3f}<br>z: %{z:.3f}<extra></extra>'\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(text=title, x=0.5, xanchor='center'),\n",
    "        scene=dict(\n",
    "            xaxis_title='X',\n",
    "            yaxis_title='Y',\n",
    "            zaxis_title='Z',\n",
    "            camera=dict(eye=dict(x=1.5, y=1.5, z=1.5))\n",
    "        ),\n",
    "        width=1000,\n",
    "        height=700,\n",
    "        showlegend=True,\n",
    "        legend=dict(x=0.02, y=0.98, bgcolor='rgba(255,255,255,0.8)')\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def generate_sample_point_cloud(n_points=1000, shape='sphere', noise_level=0.0):\n",
    "    \"\"\"Generate sample point cloud data with optional noise\"\"\"\n",
    "    if shape == 'sphere':\n",
    "        # Generate points on a sphere\n",
    "        theta = np.random.uniform(0, 2*np.pi, n_points)\n",
    "        phi = np.random.uniform(0, np.pi, n_points)\n",
    "        r = np.random.uniform(0.8, 1.2, n_points)\n",
    "        \n",
    "        x = r * np.sin(phi) * np.cos(theta)\n",
    "        y = r * np.sin(phi) * np.sin(theta)\n",
    "        z = r * np.cos(phi)\n",
    "    elif shape == 'cube':\n",
    "        # Generate points in a cube\n",
    "        x = np.random.uniform(-1, 1, n_points)\n",
    "        y = np.random.uniform(-1, 1, n_points)\n",
    "        z = np.random.uniform(-1, 1, n_points)\n",
    "    elif shape == 'torus':\n",
    "        # Generate points on a torus\n",
    "        theta = np.random.uniform(0, 2*np.pi, n_points)\n",
    "        phi = np.random.uniform(0, 2*np.pi, n_points)\n",
    "        R, r = 1.0, 0.3  # Major and minor radius\n",
    "        \n",
    "        x = (R + r * np.cos(phi)) * np.cos(theta)\n",
    "        y = (R + r * np.cos(phi)) * np.sin(theta)\n",
    "        z = r * np.sin(phi)\n",
    "    elif shape == 'cylinder':\n",
    "        # Generate points on a cylinder\n",
    "        theta = np.random.uniform(0, 2*np.pi, n_points)\n",
    "        z = np.random.uniform(-1, 1, n_points)\n",
    "        r = np.random.uniform(0.8, 1.0, n_points)\n",
    "        \n",
    "        x = r * np.cos(theta)\n",
    "        y = r * np.sin(theta)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown shape: {shape}\")\n",
    "    \n",
    "    points = np.stack([x, y, z], axis=1).astype(np.float32)\n",
    "    \n",
    "    # Add noise if specified\n",
    "    if noise_level > 0:\n",
    "        noise = np.random.randn(*points.shape) * noise_level\n",
    "        points += noise.astype(np.float32)\n",
    "    \n",
    "    # Add random features (e.g., RGB colors)\n",
    "    features = np.random.rand(n_points, 3).astype(np.float32)\n",
    "    \n",
    "    return points, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830ba343-68a4-429d-b157-271e8b3dc38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = ['sphere', 'cube', 'torus', 'cylinder']\n",
    "point_clouds = {}\n",
    "\n",
    "for shape in shapes:\n",
    "    points, features = generate_sample_point_cloud(2000, shape)\n",
    "    point_clouds[shape] = points\n",
    "    \n",
    "# Visualize individual shape\n",
    "points_sphere, features_sphere = generate_sample_point_cloud(5000, 'sphere', noise_level=0.02)\n",
    "print(f\"Points shape: {points_sphere.shape}\")\n",
    "print(f\"Features shape: {features_sphere.shape}\")\n",
    "\n",
    "# Interactive visualization with color by height\n",
    "fig = visualize_point_cloud(\n",
    "    points_sphere, \n",
    "    colors=points_sphere[:, 2],  # Color by z-coordinate\n",
    "    title=\"Interactive Sphere Point Cloud (5000 points)\",\n",
    "    point_size=2,\n",
    "    colorscale='Viridis'\n",
    ")\n",
    "\n",
    "# Visualize all shapes together for comparison\n",
    "visualize_multiple_point_clouds(point_clouds, title=\"Comparison of Different Point Cloud Shapes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c18924-d43b-4111-a4bc-18ba977ed6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warpconvnet.geometry.types.points import Points\n",
    "\n",
    "points_tensor = torch.from_numpy(points).to(device)\n",
    "features_tensor = torch.from_numpy(features).to(device)\n",
    "\n",
    "# Create batch indices (single batch for now)\n",
    "batch_indices = torch.zeros(len(points), dtype=torch.long).to(device)\n",
    "\n",
    "# Create PointCloud object\n",
    "point_cloud = Points(\n",
    "    [points_tensor],\n",
    "    [features_tensor],\n",
    ")\n",
    "print(point_cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abf5c5a-db58-4ab4-8ab8-5e6b7919a84e",
   "metadata": {},
   "source": [
    "## Voxel Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b6e850-41ff-42e6-8180-2a6c6d73af2e",
   "metadata": {},
   "source": [
    "## Conversion between PointCloud and Voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e44f9-7e87-4647-829a-d87755f307ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_voxels(voxel_coords, voxel_size=0.1, colors=None, title=\"Sparse Voxels\"):\n",
    "    \"\"\"\n",
    "    Visualize sparse voxels as 3D cubes\n",
    "    \"\"\"\n",
    "    if isinstance(voxel_coords, torch.Tensor):\n",
    "        voxel_coords = voxel_coords.cpu().numpy()\n",
    "    \n",
    "    # Create mesh for voxels\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # If no colors provided, color by height\n",
    "    if colors is None:\n",
    "        colors = voxel_coords[:, 2]\n",
    "    elif isinstance(colors, torch.Tensor):\n",
    "        colors = colors.cpu().numpy()\n",
    "    \n",
    "    # Normalize colors for visualization\n",
    "    if len(colors.shape) > 1:\n",
    "        colors = colors[:, 0]\n",
    "    \n",
    "    # Add voxels as 3D scatter with cube markers\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=voxel_coords[:, 0],\n",
    "        y=voxel_coords[:, 1],\n",
    "        z=voxel_coords[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=5,\n",
    "            color=colors,\n",
    "            colorscale='Viridis',\n",
    "            showscale=True,\n",
    "            symbol='square',\n",
    "            colorbar=dict(\n",
    "                title=\"Value\",\n",
    "                thickness=20,\n",
    "                len=0.7\n",
    "            )\n",
    "        ),\n",
    "        text=[f\"Voxel {i}<br>x: {x:.2f}<br>y: {y:.2f}<br>z: {z:.2f}\" \n",
    "              for i, (x, y, z) in enumerate(voxel_coords[:min(500, len(voxel_coords))])],\n",
    "        hovertemplate='%{text}<extra></extra>',\n",
    "        name='Voxels'\n",
    "    ))\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=dict(text=title, x=0.5, xanchor='center'),\n",
    "        scene=dict(\n",
    "            xaxis_title='X',\n",
    "            yaxis_title='Y',\n",
    "            zaxis_title='Z',\n",
    "            camera=dict(eye=dict(x=1.5, y=1.5, z=1.5)),\n",
    "            aspectmode='data'\n",
    "        ),\n",
    "        width=900,\n",
    "        height=700,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495b923c-4259-4246-9e12-0de2ac46fdf0",
   "metadata": {},
   "source": [
    "### Point Clouds -> Voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eafa4e-bad1-4446-83fa-788abaa8ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sparse voxel representation with different resolutions\n",
    "voxel_sizes = [0.05, 0.1, 0.2]\n",
    "voxel_representations = {}\n",
    "\n",
    "for voxel_size in voxel_sizes:\n",
    "    sparse_voxels = point_cloud.to_voxels(voxel_size)\n",
    "    voxel_representations[f\"Size {voxel_size}\"] = sparse_voxels\n",
    "    visualize_voxels(sparse_voxels.coordinates, sparse_voxels.voxel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c8bdbe-a74e-4844-a241-776fd826cf0f",
   "metadata": {},
   "source": [
    "### Quiz: Voxels -> Point Clouds\n",
    "- reference: https://github.com/NVlabs/WarpConvNet/blob/eda68fa3e3759dddadfc53d76038fd9246bbf885/warpconvnet/geometry/types/voxels.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4931253-e533-40d3-bb5c-09f0462b9b6d",
   "metadata": {},
   "source": [
    "## SparseConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ba7db-b430-48cc-89c2-871ee4d5863d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb96c05e-c772-4b26-b76d-8e61558a598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from warpconvnet.nn.modules.sparse_conv import SparseConv3d\n",
    "\n",
    "\n",
    "class SparseConvNet(nn.Module):\n",
    "    \"\"\"Simple sparse voxel convolution network\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels=3, out_channels=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Sparse convolution layers\n",
    "        self.conv1 = SparseConv3d(in_channels, 16, kernel_size=3, stride=1)\n",
    "        self.conv2 = SparseConv3d(16, 32, kernel_size=3, stride=2)\n",
    "        self.conv3 = SparseConv3d(32, out_channels, kernel_size=3, stride=1)\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.bn3 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        self.sparse_conv = Sequential(\n",
    "            SparseConv3d(in_channels, 16, kernel_size=3, stride=1),\n",
    "            nn.LayerNorm(16),\n",
    "            nn.ReLU(),\n",
    "            SparseConv3d(16, 32, kernel_size=2, stride=2),  # stride\n",
    "            nn.LayerNorm(32),\n",
    "            nn.ReLU(),\n",
    "            SparseConv3d(32, 64, kernel_size=3, stride=1),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.ReLU(),\n",
    "            SparseConv3d(64, 128, kernel_size=2, stride=2),  # stride\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            SparseConv3d(128, 256, kernel_size=3, stride=1),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, sparse_voxels):\n",
    "        return self.sparse_conv(sparse_voxels)\n",
    "\n",
    "# Create and test the network\n",
    "sparse_net = SparseVoxelNet(in_channels=3, out_channels=64).to(device)\n",
    "output_voxels = sparse_net(sparse_voxels)\n",
    "\n",
    "print(f\"Input voxels: {sparse_voxels}\")\n",
    "print(f\"Output voxels: {output_voxels}\")\n",
    "print(f\"Output feature dims: {output_voxels.features.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d1060e-1895-485b-b91f-eaf9662404cc",
   "metadata": {},
   "source": [
    "## Exercise 1: 3D Point Cloud Semantic Segmentation with SparseConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308f29f1-4ce6-44eb-862b-18579b242d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "import yaml\n",
    "\n",
    "try:\n",
    "    import hydra\n",
    "    from hydra.core.config_store import ConfigStore\n",
    "    from omegaconf import DictConfig, OmegaConf\n",
    "except ImportError:\n",
    "    print(\"Hydra and OmegaConf not installed, pip install hydra-core omegaconf\")\n",
    "    exit(1)\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import warp as wp\n",
    "from torch import Tensor\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "from tqdm import tqdm\n",
    "from warpconvnet.dataset.scannet import ScanNetDataset\n",
    "from warpconvnet.geometry.base.geometry import Geometry\n",
    "from warpconvnet.geometry.types.points import Points\n",
    "from warpconvnet.nn.modules.sparse_pool import PointToSparseWrapper\n",
    "\n",
    "from mink_unet import MinkUNetBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d62539-b090-4465-8f90-abef95be4836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def collate_fn(batch: List[Dict[str, Tensor]]):\n",
    "    \"\"\"\n",
    "    Return dict of list of tensors\n",
    "    \"\"\"\n",
    "    keys = batch[0].keys()\n",
    "    return {key: [torch.tensor(item[key]) for item in batch] for key in keys}\n",
    "\n",
    "\n",
    "class DataToTensor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        device: str = \"cuda\",\n",
    "    ):\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, batch_dict: Dict[str, Tensor]) -> Tuple[Geometry, Dict[str, Tensor]]:\n",
    "        # cat all features into a single tensor\n",
    "        cat_batch_dict = {k: torch.cat(v, dim=0).to(self.device) for k, v in batch_dict.items()}\n",
    "        return (\n",
    "            Points.from_list_of_coordinates(\n",
    "                batch_dict[\"coords\"],\n",
    "                features=batch_dict[\"colors\"],\n",
    "            ).to(self.device),\n",
    "            cat_batch_dict,\n",
    "        )\n",
    "\n",
    "\n",
    "def confusion_matrix_to_metrics(conf_matrix: Tensor) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Return accuracy, miou, class_iou, class_accuracy\n",
    "\n",
    "    Rows are ground truth, columns are predictions.\n",
    "    \"\"\"\n",
    "    conf_matrix = conf_matrix.cpu()\n",
    "    accuracy = (conf_matrix.diag().sum() / conf_matrix.sum()).item() * 100\n",
    "    class_accuracy = (conf_matrix.diag() / conf_matrix.sum(dim=1)) * 100\n",
    "    class_iou = conf_matrix.diag() / (\n",
    "        conf_matrix.sum(dim=1) + conf_matrix.sum(dim=0) - conf_matrix.diag()\n",
    "    )\n",
    "    miou = class_iou.mean().item() * 100\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"miou\": miou,\n",
    "        \"class_iou\": class_iou,\n",
    "        \"class_accuracy\": class_accuracy,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dbb3d4-6c87-4176-a699-63748098fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.amp.autocast(device_type=\"cuda\", enabled=True)\n",
    "def train(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    optimizer: optim.Optimizer,\n",
    "    epoch: int,\n",
    "    cfg: DictConfig,\n",
    "):\n",
    "    model.train()\n",
    "    bar = tqdm(train_loader)\n",
    "    dict_to_data = DataToTensor(device=cfg.device)\n",
    "    for batch_dict in bar:\n",
    "        start_time = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        st, batch_dict = dict_to_data(batch_dict)\n",
    "        output = model(st.to(cfg.device))\n",
    "        loss = F.cross_entropy(\n",
    "            output.features,\n",
    "            batch_dict[\"labels\"].long().to(cfg.device),\n",
    "            reduction=\"mean\",\n",
    "            ignore_index=cfg.data.ignore_index,\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        bar.set_description(f\"Train Epoch: {epoch} Loss: {loss.item(): .3f}\")\n",
    "\n",
    "\n",
    "@torch.amp.autocast(device_type=\"cuda\", enabled=True)\n",
    "@torch.inference_mode()\n",
    "def test(\n",
    "    model: nn.Module,\n",
    "    test_loader: DataLoader,\n",
    "    cfg: DictConfig,\n",
    "    num_test_batches: Optional[int] = None,\n",
    "    save_visuals: bool = False,\n",
    "):\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    confusion_matrix = MulticlassConfusionMatrix(\n",
    "        num_classes=cfg.data.num_classes, ignore_index=cfg.data.ignore_index\n",
    "    ).to(cfg.device)\n",
    "    test_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    visual_data = []\n",
    "    dict_to_data = DataToTensor(device=cfg.device)\n",
    "    for batch_dict in tqdm(test_loader):\n",
    "        original_batch_dict = batch_dict\n",
    "        st, batch_dict = dict_to_data(batch_dict)\n",
    "        output = model(st.to(cfg.device))\n",
    "        labels = batch_dict[\"labels\"].long().to(cfg.device)\n",
    "        test_loss += F.cross_entropy(\n",
    "            output.features,\n",
    "            labels,\n",
    "            reduction=\"mean\",\n",
    "            ignore_index=cfg.data.ignore_index,\n",
    "        ).item()\n",
    "        pred = output.features.argmax(dim=1)\n",
    "        confusion_matrix.update(pred, labels)\n",
    "\n",
    "        if save_visuals:\n",
    "            num_items_in_batch = len(st.offsets) - 1\n",
    "            for i in range(num_items_in_batch):\n",
    "                start_idx = st.offsets[i]\n",
    "                end_idx = st.offsets[i+1]\n",
    "\n",
    "                visual_data.append({\n",
    "                    \"coords\": original_batch_dict[\"coords\"][i],\n",
    "                    \"colors\": original_batch_dict[\"colors\"][i],\n",
    "                    \"preds\": pred[start_idx:end_idx].cpu(),\n",
    "                    \"labels\": labels[start_idx:end_idx].cpu(),\n",
    "                })\n",
    "        \n",
    "        num_batches += 1\n",
    "        if num_test_batches is not None and num_batches >= num_test_batches:\n",
    "            break\n",
    "\n",
    "    if save_visuals and visual_data:\n",
    "        save_path = cfg.paths.output_dir + \"visual_predictions.pt\"\n",
    "        os.makedirs(cfg.paths.output_dir, exist_ok=True)\n",
    "        torch.save(visual_data, save_path)\n",
    "        print(f\"\\nSaved visualization data for {len(visual_data)} point clouds to {save_path}\")\n",
    "\n",
    "    metrics = confusion_matrix_to_metrics(confusion_matrix.compute())\n",
    "    \n",
    "    print(\n",
    "        f\"\\nTest set: Average loss: {test_loss / num_batches: .4f}, Accuracy: {metrics['accuracy']: .2f}%, mIoU: {metrics['miou']: .2f}%\\n\"\n",
    "    )\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1df6567-4c5d-4f50-adef-66a1e1560864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedded YAML configuration\n",
    "CONFIG_YAML_BASE = \"\"\"\n",
    "# Path configuration\n",
    "paths:\n",
    "  data_dir: /data/scannet_3d\n",
    "  output_dir: ./results/scannet_3d\n",
    "  ckpt_path: null\n",
    "\n",
    "# Training configuration.\n",
    "train:\n",
    "  batch_size: 32\n",
    "  lr: 0.005\n",
    "  epochs: 2\n",
    "  step_size: 20\n",
    "  gamma: 0.7\n",
    "  num_workers: 8\n",
    "\n",
    "# Testing configuration\n",
    "test:\n",
    "  batch_size: 12\n",
    "  num_workers: 4\n",
    "\n",
    "# Dataset configuration\n",
    "data:\n",
    "  num_classes: 20\n",
    "  voxel_size: 0.02\n",
    "  ignore_index: 255\n",
    "\n",
    "# Model configuration\n",
    "model:\n",
    "  _target_: mink_unet.MinkUNet18\n",
    "  in_channels: 3\n",
    "  out_channels: 20\n",
    "  in_type: \"voxel\"\n",
    "\n",
    "# General configuration\n",
    "device: \"cuda\"\n",
    "use_wandb: false\n",
    "seed: 42\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ba737f-fa58-4594-bb55-2c90d11e0b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configs\n",
    "cfg_dict = yaml.safe_load(CONFIG_YAML_BASE)\n",
    "cfg = OmegaConf.create(cfg_dict)\n",
    "\n",
    "set_seed(cfg.seed)\n",
    "device = torch.device(cfg.device)\n",
    "\n",
    "# Define dataloaders\n",
    "train_dataset = ScanNetDataset(cfg.paths.data_dir, split=\"train\",)\n",
    "train_dataset = Subset(train_dataset, range(100))\n",
    "test_dataset = ScanNetDataset(cfg.paths.data_dir, split=\"val\",)\n",
    "test_dataset = Subset(test_dataset, range(50))\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=cfg.train.batch_size,\n",
    "    num_workers=cfg.train.num_workers,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=cfg.test.batch_size,\n",
    "    num_workers=cfg.test.num_workers,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "# Model initialization\n",
    "model = MinkUNetBase(\n",
    "    in_channels=cfg.model.in_channels,\n",
    "    out_channels=cfg.model.out_channels,\n",
    ").to(device)\n",
    "\n",
    "if hasattr(cfg.model, \"in_type\") and cfg.model.in_type == \"voxel\":\n",
    "    model = PointToSparseWrapper(\n",
    "        inner_module=model,\n",
    "        voxel_size=cfg.data.voxel_size,\n",
    "        concat_unpooled_pc=False,\n",
    "    )\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=cfg.train.lr)\n",
    "scheduler = StepLR(optimizer, step_size=cfg.train.step_size, gamma=cfg.train.gamma)\n",
    "\n",
    "# Test before training\n",
    "metrics = test(model, test_loader, cfg, num_test_batches=5)\n",
    "\n",
    "for epoch in range(1, cfg.train.epochs + 1):\n",
    "    train(\n",
    "        model,\n",
    "        train_loader,\n",
    "        optimizer,\n",
    "        epoch,\n",
    "        cfg,\n",
    "    )\n",
    "    should_save_visuals = (epoch == cfg.train.epochs)\n",
    "    metrics = test(model, test_loader, cfg, save_visuals=should_save_visuals)\n",
    "    scheduler.step()\n",
    "\n",
    "print(f\"Final mIoU: {metrics['miou']: .2f}%\")\n",
    "\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c80e4f0-2298-486f-8808-2a3afb2876ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinkUNetCustom(MinkUNetBase):\n",
    "    def __init__(self, in_channels: int, out_channels: int, **kwargs):\n",
    "        raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b972146-94e6-4cbf-bf84-a86638d9de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedded YAML configuration\n",
    "CONFIG_YAML_CUSTOM = \"\"\"\n",
    "# Path configuration\n",
    "paths:\n",
    "  data_dir: /data/scannet_3d\n",
    "  output_dir: ./results/scannet_3d\n",
    "  ckpt_path: null\n",
    "\n",
    "# Training configuration.\n",
    "train:\n",
    "  batch_size: 64\n",
    "  lr: 0.005\n",
    "  epochs: 2\n",
    "  step_size: 20\n",
    "  gamma: 0.7\n",
    "  num_workers: 8\n",
    "\n",
    "# Testing configuration\n",
    "test:\n",
    "  batch_size: 12\n",
    "  num_workers: 4\n",
    "\n",
    "# Dataset configuration\n",
    "data:\n",
    "  num_classes: 20\n",
    "  voxel_size: 0.02\n",
    "  ignore_index: 255\n",
    "\n",
    "# Model configuration\n",
    "model:\n",
    "  _target_: mink_unet.MinkUNet18\n",
    "  in_channels: 3\n",
    "  out_channels: 20\n",
    "  in_type: \"voxel\"\n",
    "\n",
    "# General configuration\n",
    "device: \"cuda\"\n",
    "use_wandb: false\n",
    "seed: 42\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0217a666-8c3e-4ff8-b526-d153dc4d0a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configs\n",
    "cfg_dict = yaml.safe_load(CONFIG_YAML_CUSTOM)\n",
    "cfg = OmegaConf.create(cfg_dict)\n",
    "\n",
    "set_seed(cfg.seed)\n",
    "device = torch.device(cfg.device)\n",
    "\n",
    "# Define dataloaders\n",
    "train_dataset = ScanNetDataset(cfg.paths.data_dir, split=\"train\",)\n",
    "train_dataset = Subset(train_dataset, range(100))\n",
    "test_dataset = ScanNetDataset(cfg.paths.data_dir, split=\"val\",)\n",
    "test_dataset = Subset(test_dataset, range(50))\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=cfg.train.batch_size,\n",
    "    num_workers=cfg.train.num_workers,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=cfg.test.batch_size,\n",
    "    num_workers=cfg.test.num_workers,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "# Model initialization\n",
    "model = MinkUNetCustom(\n",
    "    in_channels=cfg.model.in_channels,\n",
    "    out_channels=cfg.model.out_channels,\n",
    ").to(device)\n",
    "\n",
    "if hasattr(cfg.model, \"in_type\") and cfg.model.in_type == \"voxel\":\n",
    "    model = PointToSparseWrapper(\n",
    "        inner_module=model,\n",
    "        voxel_size=cfg.data.voxel_size,\n",
    "        concat_unpooled_pc=False,\n",
    "    )\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=cfg.train.lr)\n",
    "scheduler = StepLR(optimizer, step_size=cfg.train.step_size, gamma=cfg.train.gamma)\n",
    "\n",
    "# Test before training\n",
    "metrics = test(model, test_loader, cfg, num_test_batches=5)\n",
    "\n",
    "for epoch in range(1, cfg.train.epochs + 1):\n",
    "    train(\n",
    "        model,\n",
    "        train_loader,\n",
    "        optimizer,\n",
    "        epoch,\n",
    "        cfg,\n",
    "    )\n",
    "    should_save_visuals = (epoch == cfg.train.epochs)\n",
    "    metrics = test(model, test_loader, cfg, save_visuals=should_save_visuals)\n",
    "    scheduler.step()\n",
    "\n",
    "print(f\"Final mIoU: {metrics['miou']: .2f}%\")\n",
    "\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1225c8-161e-4d88-9f0f-531b209fd472",
   "metadata": {},
   "source": [
    "## Exercise 2: 3D Point Cloud Semantic Segmentation with PointTransformerV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d41b7f3-145c-463f-b1ea-943e7abb1028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedded YAML configuration\n",
    "CONFIG_YAML_PTV3 = \"\"\"\n",
    "# Path configuration\n",
    "paths:\n",
    "  data_dir: /data/scannet_3d\n",
    "  output_dir: ./results/scannet_3d\n",
    "  ckpt_path: null\n",
    "\n",
    "# Training configuration.\n",
    "train:\n",
    "  batch_size: 4\n",
    "  lr: 0.001\n",
    "  epochs: 2\n",
    "  step_size: 20\n",
    "  gamma: 0.7\n",
    "  num_workers: 8\n",
    "\n",
    "# Testing configuration\n",
    "test:\n",
    "  batch_size: 8\n",
    "  num_workers: 4\n",
    "\n",
    "# Dataset configuration\n",
    "data:\n",
    "  num_classes: 20\n",
    "  voxel_size: 0.02\n",
    "  ignore_index: 255\n",
    "\n",
    "# Model configuration\n",
    "model:\n",
    "  _target_: mink_unet.MinkUNet18\n",
    "  in_channels: 3\n",
    "  out_channels: 20\n",
    "  in_type: \"voxel\"\n",
    "\n",
    "# General configuration\n",
    "device: \"cuda\"\n",
    "use_wandb: false\n",
    "seed: 42\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aec18aa-0ecd-4e73-885e-33474321b252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from point_transformer_v3 import PointTransformerV3\n",
    "\n",
    "# Load configs\n",
    "cfg_dict = yaml.safe_load(CONFIG_YAML_PTV3)\n",
    "cfg = OmegaConf.create(cfg_dict)\n",
    "\n",
    "set_seed(cfg.seed)\n",
    "device = torch.device(cfg.device)\n",
    "\n",
    "# Define dataloaders\n",
    "train_dataset = ScanNetDataset(cfg.paths.data_dir, split=\"train\",)\n",
    "train_dataset = Subset(train_dataset, range(100))\n",
    "test_dataset = ScanNetDataset(cfg.paths.data_dir, split=\"val\",)\n",
    "test_dataset = Subset(test_dataset, range(50))\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=cfg.train.batch_size,\n",
    "    num_workers=cfg.train.num_workers,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=cfg.test.batch_size,\n",
    "    num_workers=cfg.test.num_workers,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "# Model initialization\n",
    "model = PointTransformerV3(\n",
    "    in_channels=cfg.model.in_channels,\n",
    "    out_channels=cfg.model.out_channels,\n",
    ").to(device)\n",
    "\n",
    "if hasattr(cfg.model, \"in_type\") and cfg.model.in_type == \"voxel\":\n",
    "    model = PointToSparseWrapper(\n",
    "        inner_module=model,\n",
    "        voxel_size=cfg.data.voxel_size,\n",
    "        concat_unpooled_pc=False,\n",
    "    )\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=cfg.train.lr)\n",
    "scheduler = StepLR(optimizer, step_size=cfg.train.step_size, gamma=cfg.train.gamma)\n",
    "\n",
    "# Test before training\n",
    "metrics = test(model, test_loader, cfg, num_test_batches=5)\n",
    "\n",
    "for epoch in range(1, cfg.train.epochs + 1):\n",
    "    train(\n",
    "        model,\n",
    "        train_loader,\n",
    "        optimizer,\n",
    "        epoch,\n",
    "        cfg,\n",
    "    )\n",
    "    should_save_visuals = (epoch == cfg.train.epochs)\n",
    "    metrics = test(model, test_loader, cfg, save_visuals=should_save_visuals)\n",
    "    scheduler.step()\n",
    "\n",
    "print(f\"Final mIoU: {metrics['miou']: .2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0127f48e-1ceb-4940-a63e-fa35431eaabb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
