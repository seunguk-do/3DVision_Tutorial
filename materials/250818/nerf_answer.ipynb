{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKYHBlBi_msh"
   },
   "source": [
    "# NeRF Tutorial\n",
    "\n",
    "This notebook was created for the AI Expert course on August 22nd.\n",
    "This material explores the basics and applications of NeRF. For theoretical background on NeRF, please refer to the following paper: [NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis](https://arxiv.org/abs/2003.08934).\n",
    "\n",
    "## Table of Contents\n",
    "* TinyNeRF\n",
    "* NeRFStudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAgZJrG3CaBr"
   },
   "source": [
    "# 1. TinyNeRF\n",
    "\n",
    "A NeRF model with reduced performance for fast training and visualization\n",
    "* Approximately 20 times fewer parameters compared to the original NeRF\n",
    "* 5D input does not include view direction\n",
    "* Does not perform Hierarchical Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10916,
     "status": "ok",
     "timestamp": 1692670440491,
     "user": {
      "displayName": "Seunguk Do",
      "userId": "05447261647661672061"
     },
     "user_tz": -540
    },
    "id": "KeYif4s5C3-n",
    "outputId": "5f8bb572-da80-4431-e1e4-16ed867967db"
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not os.path.exists('tiny_nerf_data.npz'):\n",
    "    !wget http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/ECCV20/nerf/tiny_nerf_data.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UMjbXlumD-v6"
   },
   "outputs": [],
   "source": [
    "#Search for GPU to run on\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#Load in data\n",
    "rawData = np.load(\"tiny_nerf_data.npz\")\n",
    "images = rawData[\"images\"]\n",
    "poses = rawData[\"poses\"]\n",
    "focal = rawData[\"focal\"]\n",
    "H, W = images.shape[1:3]\n",
    "H = int(H)\n",
    "W = int(W)\n",
    "print(images.shape, poses.shape, focal)\n",
    "\n",
    "testimg, testpose = images[99], poses[99]\n",
    "plt.imshow(testimg)\n",
    "plt.show()\n",
    "images = torch.Tensor(images).to(device)\n",
    "poses = torch.Tensor(poses).to(device)\n",
    "testimg = torch.Tensor(testimg).to(device)\n",
    "testpose = torch.Tensor(testpose).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DwElRchlEhvG"
   },
   "outputs": [],
   "source": [
    "def get_rays(H, W, focal, pose):\n",
    "  i, j = torch.meshgrid(\n",
    "      torch.arange(W, dtype=torch.float32),\n",
    "      torch.arange(H, dtype=torch.float32)\n",
    "      )\n",
    "  i = i.t()\n",
    "  j = j.t()\n",
    "  dirs = torch.stack(\n",
    "      [(i-W*0.5)/focal,\n",
    "       -(j-H*0.5)/focal,\n",
    "       -torch.ones_like(i)], -1).to(device)\n",
    "  rays_d = torch.sum(dirs[..., np.newaxis, :] * pose[:3, :3], -1)\n",
    "  rays_o = pose[:3,-1].expand(rays_d.shape)\n",
    "  return rays_o, rays_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUN2AS7VFNkR"
   },
   "outputs": [],
   "source": [
    "def positional_encoder(x, L_embed=6):\n",
    "  rets = [x]\n",
    "  for i in range(L_embed):\n",
    "    for fn in [torch.sin, torch.cos]:\n",
    "      rets.append(fn(2.**i *x))#(2^i)*x\n",
    "  return torch.cat(rets, -1)\n",
    "\n",
    "def cumprod_exclusive(tensor: torch.Tensor) -> torch.Tensor:\n",
    "  cumprod = torch.cumprod(tensor, -1)\n",
    "  cumprod = torch.roll(cumprod, 1, -1)\n",
    "  cumprod[..., 0] = 1.\n",
    "  return cumprod\n",
    "\n",
    "def render(model, rays_o, rays_d, near, far, n_samples, rand=False):\n",
    "  def batchify(fn, chunk=1024*32):\n",
    "      return lambda inputs: torch.cat([fn(inputs[i:i+chunk]) for i in range(0, inputs.shape[0], chunk)], 0)\n",
    "\n",
    "  z = torch.linspace(near, far, n_samples).to(device)\n",
    "  if rand:\n",
    "    mids = 0.5 * (z[..., 1:] + z[...,:-1])\n",
    "    upper = torch.cat([mids, z[...,-1:]], -1)\n",
    "    lower = torch.cat([z[...,:1], mids], -1)\n",
    "    t_rand = torch.rand(z.shape).to(device)\n",
    "    z = lower + (upper-lower)*t_rand\n",
    "\n",
    "  points = rays_o[..., None,:] + rays_d[..., None,:] * z[...,:,None]\n",
    "\n",
    "  flat_points = torch.reshape(points, [-1, points.shape[-1]])\n",
    "  flat_points = positional_encoder(flat_points)\n",
    "  raw = batchify(model)(flat_points)\n",
    "  raw = torch.reshape(raw, list(points.shape[:-1]) + [4])\n",
    "\n",
    "  #Compute opacitices and color\n",
    "  sigma = F.relu(raw[..., 3])\n",
    "  rgb = torch.sigmoid(raw[..., :3])\n",
    "\n",
    "  #Volume Rendering\n",
    "  one_e_10 = torch.tensor([1e10], dtype=rays_o.dtype).to(device)\n",
    "  dists = torch.cat((z[..., 1:] - z[..., :-1],\n",
    "                  one_e_10.expand(z[..., :1].shape)), dim=-1)\n",
    "  alpha = 1. - torch.exp(-sigma * dists)\n",
    "  weights = alpha * cumprod_exclusive(1. - alpha + 1e-10)\n",
    "\n",
    "  rgb_map = (weights[...,None]* rgb).sum(dim=-2)\n",
    "  depth_map = (weights * z).sum(dim=-1)\n",
    "  acc_map = weights.sum(dim=-1)\n",
    "  return rgb_map, depth_map, acc_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsBaOWyRFRc4"
   },
   "outputs": [],
   "source": [
    "#helper functions\n",
    "mse2psnr = lambda x : -10. * torch.log(x) / torch.log(torch.Tensor([10.])).to(device)\n",
    "\n",
    "def train(model, optimizer, n_iters = 3001):\n",
    "  #Track loss over time for graphing\n",
    "  psnrs = []\n",
    "  iternums = []\n",
    "  plot_step = 500\n",
    "  n_samples = 64\n",
    "  for i in range(n_iters):\n",
    "    #Choose random image and use it for training\n",
    "    images_idx = np.random.randint(images.shape[0])\n",
    "    target = images[images_idx]\n",
    "    pose = poses[images_idx]\n",
    "\n",
    "    #Core optimizer loop\n",
    "    rays_o, rays_d = get_rays(H, W, focal, pose)\n",
    "    rgb, disp, acc = render(model, rays_o, rays_d, near=2., far=6., n_samples=n_samples, rand=True)\n",
    "    optimizer.zero_grad()\n",
    "    image_loss = torch.nn.functional.mse_loss(rgb, target)\n",
    "    image_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i%plot_step==0:\n",
    "      #Render shown image above as model begins to learn\n",
    "      with torch.no_grad():\n",
    "        rays_o, rays_d = get_rays(H, W, focal, testpose)\n",
    "        rgb, depth, acc = render(model, rays_o, rays_d, near=2., far=6., n_samples=n_samples)\n",
    "        loss = torch.nn.functional.mse_loss(rgb, testimg)\n",
    "        psnr = mse2psnr(loss).cpu()\n",
    "\n",
    "        psnrs.append(psnr)\n",
    "        iternums.append(i)\n",
    "\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.subplot(121)\n",
    "        #copy from gpu memory to cpu\n",
    "        picture = rgb.cpu()\n",
    "        plt.imshow(picture)\n",
    "        plt.title(f'Iterations: {i}')\n",
    "        plt.subplot(122)\n",
    "        plt.plot(iternums, psnrs)\n",
    "        plt.title('PSNR')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1oqQwlXFU92"
   },
   "outputs": [],
   "source": [
    "class VeryTinyNerfModel(torch.nn.Module):\n",
    "  def __init__(self, filter_size=128, num_encoding_functions=6):\n",
    "    super(VeryTinyNerfModel, self).__init__()\n",
    "    # Input layer (default: 39 -> 128)\n",
    "    self.layer1 = torch.nn.Linear(3 + 3 * 2 * num_encoding_functions, filter_size)\n",
    "    # Layer 2 (default: 128 -> 128)\n",
    "    self.layer2 = torch.nn.Linear(filter_size, filter_size)\n",
    "    # Layer 3 (default: 128 -> 4)\n",
    "    self.layer3 = torch.nn.Linear(filter_size, 4)\n",
    "    # Short hand for torch.nn.functional.relu\n",
    "    self.relu = torch.nn.functional.relu\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.relu(self.layer1(x))\n",
    "    x = self.relu(self.layer2(x))\n",
    "    x = self.layer3(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGypem0xFYSv"
   },
   "outputs": [],
   "source": [
    "#Run all the actual code\n",
    "nerf = VeryTinyNerfModel()\n",
    "nerf = nn.DataParallel(nerf).to(device)\n",
    "optimizer = torch.optim.Adam(nerf.parameters(), lr=5e-3, eps = 1e-7)\n",
    "train(nerf, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cFCaTulIC4h"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interactive, widgets\n",
    "\n",
    "\n",
    "trans_t = lambda t : torch.tensor([\n",
    "    [1,0,0,0],\n",
    "    [0,1,0,0],\n",
    "    [0,0,1,t],\n",
    "    [0,0,0,1],\n",
    "], dtype=torch.float32)\n",
    "\n",
    "rot_phi = lambda phi : torch.tensor([\n",
    "    [1,0,0,0],\n",
    "    [0,np.cos(phi),-np.sin(phi),0],\n",
    "    [0,np.sin(phi), np.cos(phi),0],\n",
    "    [0,0,0,1],\n",
    "], dtype=torch.float32)\n",
    "\n",
    "rot_theta = lambda th : torch.tensor([\n",
    "    [np.cos(th),0,-np.sin(th),0],\n",
    "    [0,1,0,0],\n",
    "    [np.sin(th),0, np.cos(th),0],\n",
    "    [0,0,0,1],\n",
    "], dtype=torch.float32)\n",
    "\n",
    "\n",
    "def pose_spherical(theta, phi, radius):\n",
    "    c2w = trans_t(radius)\n",
    "    c2w = rot_phi(phi/180.*np.pi) @ c2w\n",
    "    c2w = rot_theta(theta/180.*np.pi) @ c2w\n",
    "    c2w = torch.tensor([[-1,0,0,0],[0,0,1,0],[0,1,0,0],[0,0,0,1]], dtype=torch.float32) @ c2w\n",
    "    return c2w\n",
    "\n",
    "\n",
    "def f(**kwargs):\n",
    "    c2w = pose_spherical(**kwargs).cuda()\n",
    "    rays_o, rays_d = get_rays(H, W, focal, c2w[:3,:4])\n",
    "    rgb, depth, acc = render(nerf, rays_o, rays_d, near=2., far=6., n_samples=64)\n",
    "    img = np.clip(rgb.cpu().detach().numpy(),0,1)\n",
    "\n",
    "    plt.figure(2, figsize=(20,6))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "sldr = lambda v, mi, ma: widgets.FloatSlider(\n",
    "    value=v,\n",
    "    min=mi,\n",
    "    max=ma,\n",
    "    step=.01,\n",
    ")\n",
    "\n",
    "names = [\n",
    "    ['theta', [100., 0., 360]],\n",
    "    ['phi', [-30., -90, 0]],\n",
    "    ['radius', [4., 3., 5.]],\n",
    "]\n",
    "\n",
    "interactive_plot = interactive(f, **{s[0] : sldr(*s[1]) for s in names})\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = '350px'\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6: Custom TinyNeRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTinyNerfModel(torch.nn.Module):\n",
    "    \n",
    "    ######## Implement from here ########\n",
    "    def __init__(self):\n",
    "    \n",
    "    def forward(self, x):\n",
    "    ####### End of Implementation #######\n",
    "\n",
    "nerf = CustomTinyNerfModel()\n",
    "nerf = nn.DataParallel(nerf).to(device)\n",
    "optimizer = torch.optim.Adam(nerf.parameters(), lr=5e-3, eps = 1e-7)\n",
    "train(nerf, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfkIsBFJFcxG"
   },
   "source": [
    "# 2. NeRFStudio\n",
    "\n",
    "A platform designed to easily utilize various NeRF models.\n",
    "\n",
    "* Includes multiple types of NeRF models (dynamic nerf, editing nerf, 3d diffusion model, fast nerf)\n",
    "* Supports a powerful visualizer that enables easy rendering of desired view images\n",
    "* Facilitates new model development by allowing easy modification of NeRF modules such as dataloader, ray sampler, encoder, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m_N8_cLfjoXD",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NERFSTUDIO_PORT = os.environ[\"NERFSTUDIO_PORT\"]\n",
    "!ns-train nerfacto --output-dir \"results/nerfstudio/nerfacto\" --viewer.websocket-port \"{NERFSTUDIO_PORT}\" nerfstudio-data --data /data/nerfstudio/dozer --downscale-factor 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DbfAa7PsTKYf"
   },
   "outputs": [],
   "source": [
    "#@title # Resume stopped training\n",
    "base_dir = \"./outputs/unnamed/nerfacto/\"\n",
    "training_run_dir = base_dir + os.listdir(base_dir)[0] + '/nerfstudio_models'\n",
    "\n",
    "!ns-train nerfacto --load-dir {training_run_dir} --viewer.websocket-port \"{NERFSTUDIO_PORT}\" nerfstudio-data --data data/nerfstudio/$scene --downscale-factor 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LELvyfR8ic0k"
   },
   "source": [
    "### Utilizing Various Models with NeRFStudio\n",
    "* nerfacto is a pipeline created by combining components from various papers\n",
    "* nerfstudio supports various models besides nerfacto\n",
    "  - Instant-NGP\n",
    "  - [Instruct-NeRF2NeRF](https://docs.nerf.studio/en/latest/nerfology/methods/in2n.html)\n",
    "  - K-Planes\n",
    "  - [LERF](https://docs.nerf.studio/en/latest/nerfology/methods/lerf.html)\n",
    "  - Mip-NeRF\n",
    "  - NeRF\n",
    "  - Nerfacto\n",
    "  - Nerfbusters\n",
    "  - NeRFPlayer\n",
    "  - Tetra-NeRF\n",
    "  - TensoRF\n",
    "  - [Generfacto](https://docs.nerf.studio/en/latest/nerfology/methods/generfacto.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ns-train --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNIPUivp6Uwc"
   },
   "source": [
    "#### Exercise7: Training other models than NeRFacto (Recommendation: Instant-NGP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6B1zNaz3U-p"
   },
   "outputs": [],
   "source": [
    "######## Implement from here ########\n",
    "####### End of Implementation #######"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "https://github.com/nerfstudio-project/nerfstudio/blob/main/colab/demo.ipynb",
     "timestamp": 1692614006517
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c59f626636933ef1dc834fb3684b382f705301c5306cf8436d2da634c2289783"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
