{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUBqyXw4i9rG"
   },
   "source": [
    "# SIREN Tutorial\n",
    "\n",
    "In this tutorial, we will explore the basic properties and applications of the SIREN MLP. For the theoretical background, please refer to the paper [Implicit Neural Representations with Periodic Activation Functions](https://arxiv.org/abs/2006.09661).\n",
    "\n",
    "## Table of Contents\n",
    "* Fitting an image\n",
    "* Solving Poisson's equation\n",
    "* Fitting SDF from Point Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUxbT1b7DtsF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import plyfile\n",
    "import skimage.measure\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "from torchmetrics.image import PeakSignalNoiseRatio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCSOaOmTDtsF"
   },
   "source": [
    "Define a function to generate coordinate grids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4arW7Z7Ki9rJ"
   },
   "outputs": [],
   "source": [
    "def get_mgrid(sidelen, dim=2):\n",
    "    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\n",
    "    sidelen: int\n",
    "    dim: int'''\n",
    "    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n",
    "    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
    "    mgrid = mgrid.reshape(-1, dim)\n",
    "    return mgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1692593262127,
     "user": {
      "displayName": "Seunguk Do",
      "userId": "05447261647661672061"
     },
     "user_tz": -540
    },
    "id": "KLzD2MeUa0bx",
    "outputId": "97461cb0-9594-4759-ccc2-f3f036faf645"
   },
   "outputs": [],
   "source": [
    "print(get_mgrid(256).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1692593317082,
     "user": {
      "displayName": "Seunguk Do",
      "userId": "05447261647661672061"
     },
     "user_tz": -540
    },
    "id": "x1-85G53a_6D",
    "outputId": "b3bc38c2-e39c-46e9-b6a5-33876fc130f3"
   },
   "outputs": [],
   "source": [
    "mgrid = get_mgrid(256)\n",
    "y_index = 0\n",
    "for x_index in range(0, 256, 32):\n",
    "    print(f\"The position of index [{x_index}, {y_index}] is {mgrid[x_index*256+y_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0RUUS8LnBNpH"
   },
   "source": [
    "Define functions for differential operations including Laplacian, divergence, and gradient, which are computed numerically using PyTorch's automatic differentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Xm2o-2UBTnX"
   },
   "outputs": [],
   "source": [
    "def laplace(y, x):\n",
    "    grad = gradient(y, x)\n",
    "    return divergence(grad, x)\n",
    "\n",
    "def divergence(y, x):\n",
    "    div = 0.\n",
    "    for i in range(y.shape[-1]):\n",
    "        div += torch.autograd.grad(y[..., i], x, torch.ones_like(y[..., i]), create_graph=True)[0][..., i:i+1]\n",
    "    return div\n",
    "\n",
    "def gradient(y, x, grad_outputs=None):\n",
    "    if grad_outputs is None:\n",
    "        grad_outputs = torch.ones_like(y)\n",
    "    grad = torch.autograd.grad(y, [x], grad_outputs=grad_outputs, create_graph=True)[0]\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncL598k9i9rL"
   },
   "source": [
    "<a id='section_1'></a>\n",
    "## 1. Fitting an Image\n",
    "\n",
    "In this section, we parametrize a grayscale image $f(x)$ using the SIREN function $\\Phi(x)$, where $x$ represents pixel coordinates.\n",
    "\n",
    "We optimize $\\Phi$ using the following loss function:\n",
    "$$L=\\int_{\\Omega} \\lVert \\Phi(\\mathbf{x}) - f(\\mathbf{x}) \\rVert\\mathrm{d}\\mathbf{x},$$ where $\\Omega$ represents the image domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FM5bE5S_GIrC"
   },
   "source": [
    "#### Define a PyTorch Dataset for Image Fitting\n",
    "We define a PyTorch dataset that returns pairs of pixel coordinates and their corresponding grayscale values from the cameraman image (a standard test image provided by the scikit-image library)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "executionInfo": {
     "elapsed": 2220,
     "status": "ok",
     "timestamp": 1692593131106,
     "user": {
      "displayName": "Seunguk Do",
      "userId": "05447261647661672061"
     },
     "user_tz": -540
    },
    "id": "-D3fCcMlDtsI",
    "outputId": "2f6a2380-9ccb-4312-d1a4-d86314a9e368"
   },
   "outputs": [],
   "source": [
    "plt.imshow(skimage.data.camera())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ts_R2vu5i9rM"
   },
   "outputs": [],
   "source": [
    "def get_cameraman_tensor(sidelength):\n",
    "    img = Image.fromarray(skimage.data.camera())\n",
    "    transform = Compose([\n",
    "        Resize(sidelength),\n",
    "        ToTensor(),\n",
    "        Normalize(torch.Tensor([0.5]), torch.Tensor([0.5]))\n",
    "    ])\n",
    "    img = transform(img)\n",
    "    return img\n",
    "\n",
    "class ImageFitting(Dataset):\n",
    "    def __init__(self, sidelength):\n",
    "        super().__init__()\n",
    "        img = get_cameraman_tensor(sidelength)\n",
    "        self.pixels = img.permute(1, 2, 0).view(-1, 1)\n",
    "        self.coords = get_mgrid(sidelength, 2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx > 0: raise IndexError\n",
    "\n",
    "        return self.coords, self.pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hH_8kFnwi9rM"
   },
   "source": [
    "#### Instantiate Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4883,
     "status": "ok",
     "timestamp": 1692593363255,
     "user": {
      "displayName": "Seunguk Do",
      "userId": "05447261647661672061"
     },
     "user_tz": -540
    },
    "id": "mroLvWvli9rM",
    "outputId": "842062be-dee8-4251-8386-02992a93dcec"
   },
   "outputs": [],
   "source": [
    "cameraman = ImageFitting(256)\n",
    "dataloader = DataLoader(cameraman, batch_size=1, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, log_dir, total_steps=500, log_steps=50):\n",
    "    optim = torch.optim.Adam(lr=1e-4, params=model.parameters())\n",
    "    \n",
    "    model_input, ground_truth = next(iter(dataloader))\n",
    "    model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n",
    "    \n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    with tqdm(total=total_steps) as pbar:\n",
    "        for step in range(total_steps):\n",
    "            model_output, coords = model(model_input)\n",
    "            loss = ((model_output - ground_truth)**2).mean()\n",
    "        \n",
    "            if not step % log_steps:\n",
    "                pbar.set_description(\"Step %d, Total loss %0.6f\" % (step, loss))\n",
    "                img_grad = gradient(model_output, coords)\n",
    "                img_laplacian = laplace(model_output, coords)\n",
    "        \n",
    "                # Create figure and subplots explicitly\n",
    "                fig, axes = plt.subplots(1, 3, figsize=(5, 5))\n",
    "                \n",
    "                # Plot the three images\n",
    "                axes[0].imshow(model_output.cpu().view(256,256).detach().numpy())\n",
    "                axes[0].set_title('Model Output')\n",
    "                axes[0].axis('off')\n",
    "                \n",
    "                axes[1].imshow(img_grad.norm(dim=-1).cpu().view(256,256).detach().numpy())\n",
    "                axes[1].set_title('Gradient')\n",
    "                axes[1].axis('off')\n",
    "                \n",
    "                axes[2].imshow(img_laplacian.cpu().view(256,256).detach().numpy())\n",
    "                axes[2].set_title('Laplacian')\n",
    "                axes[2].axis('off')\n",
    "                \n",
    "                # Save the figure\n",
    "                plt.savefig(log_dir / f\"{step}.png\", dpi=300, bbox_inches='tight')\n",
    "                plt.close()  # Close the figure to free memory\n",
    "    \n",
    "                psnr = PeakSignalNoiseRatio(data_range=1.0).cuda()\n",
    "                psnr_value = psnr(model_output, ground_truth)\n",
    "                \n",
    "                print(f\"Test at step {step}, PSNR: {psnr_value:0.6f}\")\n",
    "        \n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Baseline Model with ReLU Activation\n",
    "We implement a baseline model that uses ReLU activation functions for implicit neural representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLULayer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False):\n",
    "        super().__init__()\n",
    "        self.is_first = is_first\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.relu(self.linear(input))\n",
    "\n",
    "class ReLUBaseline(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = []\n",
    "        self.net.append(ReLULayer(in_features, hidden_features,\n",
    "                                  is_first=True))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(ReLULayer(hidden_features, hidden_features,\n",
    "                                      is_first=False))\n",
    "\n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "            self.net.append(final_linear)\n",
    "        else:\n",
    "            self.net.append(ReLULayer(hidden_features, out_features,\n",
    "                                      is_first=False))\n",
    "\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "\n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        return output, coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAhsenT2i9rM"
   },
   "source": [
    "#### Train the ReLU Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model\n",
    "relu_baseline = ReLUBaseline(\n",
    "    in_features=2,\n",
    "    out_features=1,\n",
    "    hidden_features=256,\n",
    "    hidden_layers=3,\n",
    "    outermost_linear=True)\n",
    "relu_baseline.cuda()\n",
    "\n",
    "# Define a dataloader\n",
    "cameraman = ImageFitting(256)\n",
    "dataloader = DataLoader(cameraman, batch_size=1, pin_memory=True, num_workers=0)\n",
    "\n",
    "# Training loop\n",
    "log_dir = Path(\"./results/siren/img_relu\")\n",
    "train(relu_baseline, dataloader, log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define SIREN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineLayer(nn.Module):\n",
    "    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n",
    "\n",
    "    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the\n",
    "    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a\n",
    "    # hyperparameter.\n",
    "\n",
    "    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of\n",
    "    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features,\n",
    "                                             1 / self.in_features)\n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0,\n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        ######## Implement from here ########\n",
    "        ####### End of Implementation #######\n",
    "\n",
    "    def forward_with_intermediate(self, input):\n",
    "        # For visualization of activation distributions\n",
    "        intermediate = self.omega_0 * self.linear(input)\n",
    "        return torch.sin(intermediate), intermediate\n",
    "\n",
    "class Siren(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False,\n",
    "                 first_omega_0=30, hidden_omega_0=30.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = []\n",
    "        self.net.append(SineLayer(in_features, hidden_features,\n",
    "                                  is_first=True, omega_0=first_omega_0))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(SineLayer(hidden_features, hidden_features,\n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        if outermost_linear:\n",
    "            final_linear = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0,\n",
    "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
    "\n",
    "            self.net.append(final_linear)\n",
    "        else:\n",
    "            self.net.append(SineLayer(hidden_features, out_features,\n",
    "                                      is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "\n",
    "    def forward(self, coords):\n",
    "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
    "        output = self.net(coords)\n",
    "        return output, coords\n",
    "\n",
    "    def forward_with_activations(self, coords, retain_grad=False):\n",
    "        '''Returns not only model output, but also intermediate activations.\n",
    "        Only used for visualizing activations later!'''\n",
    "        activations = OrderedDict()\n",
    "\n",
    "        activation_count = 0\n",
    "        x = coords.clone().detach().requires_grad_(True)\n",
    "        activations['input'] = x\n",
    "        for i, layer in enumerate(self.net):\n",
    "            if isinstance(layer, SineLayer):\n",
    "                x, intermed = layer.forward_with_intermediate(x)\n",
    "\n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "                    intermed.retain_grad()\n",
    "\n",
    "                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n",
    "                activation_count += 1\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "                if retain_grad:\n",
    "                    x.retain_grad()\n",
    "\n",
    "            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n",
    "            activation_count += 1\n",
    "\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Train the SIREN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_dir = Path(\"./results/siren/img_siren\")\n",
    "\n",
    "######## Implement from here ########\n",
    "\n",
    "####### End of Implementation #######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NeDZnt4i9rP"
   },
   "source": [
    "<a id='section_3'></a>\n",
    "## 2. Solving Poisson's Equation\n",
    "\n",
    "This section demonstrates how to reconstruct an original image when only gradient information is available.\n",
    "\n",
    "We optimize $\\Phi$ using the following loss function:\n",
    "$$L=\\int_{\\Omega} \\lVert \\nabla\\Phi(\\mathbf{x}) - \\nabla f(\\mathbf{x}) \\rVert\\mathrm{d}\\mathbf{x},$$ where $\\Omega$ represents the image domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcnz1Y8tDtsK"
   },
   "source": [
    "#### Define PyTorch Dataset for Solving Poisson's Equation\n",
    "Similar to Section 1, we use the cameraman image. This dataset returns pixel coordinates along with their corresponding grayscale values, gradients, and Laplacian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IbMkZsw7i9rP"
   },
   "outputs": [],
   "source": [
    "import scipy.ndimage\n",
    "\n",
    "class PoissonEqn(Dataset):\n",
    "    def __init__(self, sidelength):\n",
    "        super().__init__()\n",
    "        img = get_cameraman_tensor(sidelength)\n",
    "\n",
    "        ######## Implement from here ########\n",
    "        # Compute gradient and laplacian\n",
    "        # Refer: https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.sobel.html\n",
    "        grads_x =\n",
    "        grads_y = \n",
    "        ####### End of Implementation #######\n",
    "        grads_x, grads_y = torch.from_numpy(grads_x), torch.from_numpy(grads_y)\n",
    "\n",
    "        self.grads = torch.stack((grads_x, grads_y), dim=-1).view(-1, 2)\n",
    "        self.laplace = scipy.ndimage.laplace(img.numpy()).squeeze(0)[..., None]\n",
    "        self.laplace = torch.from_numpy(self.laplace)\n",
    "\n",
    "        self.pixels = img.permute(1, 2, 0).view(-1, 1)\n",
    "        self.coords = get_mgrid(sidelength, 2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.coords, {'pixels':self.pixels, 'grads':self.grads, 'laplace':self.laplace}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "executionInfo": {
     "elapsed": 3445,
     "status": "ok",
     "timestamp": 1692596077737,
     "user": {
      "displayName": "Seunguk Do",
      "userId": "05447261647661672061"
     },
     "user_tz": -540
    },
    "id": "HI0RAkY1DtsK",
    "outputId": "5d6311cd-af6e-45a3-b4d9-20b12ba1ddd9"
   },
   "outputs": [],
   "source": [
    "img = get_cameraman_tensor(256)\n",
    "\n",
    "grads_x = scipy.ndimage.sobel(img.numpy(), axis=1).squeeze(0)[..., None]\n",
    "grads_y = scipy.ndimage.sobel(img.numpy(), axis=2).squeeze(0)[..., None]\n",
    "grads_x, grads_y = torch.from_numpy(grads_x), torch.from_numpy(grads_y)\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,6))\n",
    "axes[0].imshow(grads_x)\n",
    "axes[1].imshow(grads_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDYETmb0i9rP"
   },
   "source": [
    "#### Instantiate Dataset and SIREN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients_mse(model_output, coords, gt_gradients):\n",
    "    # compute gradients on the model\n",
    "    gradients = gradient(model_output, coords)\n",
    "    # compare them with the ground-truth\n",
    "    gradients_loss = torch.mean((gradients - gt_gradients).pow(2).sum(-1))\n",
    "    return gradients_loss\n",
    "\n",
    "def train(model, dataloader, log_dir, total_steps=500, log_steps=50):\n",
    "    optim = torch.optim.Adam(lr=1e-4, params=relu_baseline.parameters())\n",
    "    \n",
    "    model_input, ground_truth = next(iter(dataloader))\n",
    "    model_input = model_input.cuda()\n",
    "    gt = {key: value.cuda() for key, value in ground_truth.items()}\n",
    "    \n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    with tqdm(total=total_steps) as pbar:\n",
    "        for step in range(total_steps):\n",
    "            model_output, coords = model(model_input)\n",
    "            loss = gradients_mse(model_output, coords, gt['grads'])\n",
    "        \n",
    "            if not step % log_steps:\n",
    "                pbar.set_description(\"Step %d, Total loss %0.6f\" % (step, loss))\n",
    "                img_grad = gradient(model_output, coords)\n",
    "                img_laplacian = laplace(model_output, coords)\n",
    "        \n",
    "                # Create figure and subplots explicitly\n",
    "                fig, axes = plt.subplots(1, 3, figsize=(5, 5))\n",
    "                \n",
    "                # Plot the three images\n",
    "                axes[0].imshow(model_output.cpu().view(128,128).detach().numpy())\n",
    "                axes[0].set_title('Model Output')\n",
    "                axes[0].axis('off')\n",
    "                \n",
    "                axes[1].imshow(img_grad.norm(dim=-1).cpu().view(128,128).detach().numpy())\n",
    "                axes[1].set_title('Gradient')\n",
    "                axes[1].axis('off')\n",
    "                \n",
    "                axes[2].imshow(img_laplacian.cpu().view(128,128).detach().numpy())\n",
    "                axes[2].set_title('Laplacian')\n",
    "                axes[2].axis('off')\n",
    "                \n",
    "                # Save the figure\n",
    "                plt.savefig(log_dir / f\"{step}.png\", dpi=300, bbox_inches='tight')\n",
    "                plt.close()  # Close the figure to free memory\n",
    "    \n",
    "                psnr = PeakSignalNoiseRatio(data_range=1.0).cuda()\n",
    "                psnr_value = psnr(model_output, gt['pixels'])\n",
    "                \n",
    "                print(f\"Test at step {step}, PSNR: {psnr_value:0.6f}\")\n",
    "        \n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1692596174615,
     "user": {
      "displayName": "Seunguk Do",
      "userId": "05447261647661672061"
     },
     "user_tz": -540
    },
    "id": "Vo0AD2Vhi9rQ",
    "outputId": "eb858ea6-b671-41ed-f4ca-1997c67cbd7a"
   },
   "outputs": [],
   "source": [
    "cameraman_poisson = PoissonEqn(128)\n",
    "dataloader = DataLoader(cameraman_poisson, batch_size=1, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcAkujrWi9rQ"
   },
   "source": [
    "#### Exercise 2: Train the ReLU Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_baseline = ReLUBaseline(\n",
    "    in_features=2,\n",
    "    out_features=1,\n",
    "    hidden_features=256,\n",
    "    hidden_layers=3,\n",
    "    outermost_linear=True)\n",
    "relu_baseline.cuda()\n",
    "\n",
    "log_dir = Path(\"./results/siren/img_poisson_relu\")\n",
    "train(relu_baseline, dataloader, log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3: Train SIREN Model on Poisson's Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_dir = Path(\"./results/siren/img_poisson_siren\")\n",
    "######## Implement from here ########\n",
    "\n",
    "####### End of Implementation #######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hu3Jx_uVSaJf"
   },
   "source": [
    "## 3. Fitting SDF from Point Clouds\n",
    "\n",
    "This section demonstrates how to reconstruct a 3D surface from a given point cloud.\n",
    "The 3D surface is represented as a Signed Distance Field (SDF) $\\Phi: x \\rightarrow s$, where $x$ represents 3D coordinates and $s$ represents the distance to the surface.\n",
    "\n",
    "We optimize $\\Phi$ using the following loss function $L$:\n",
    "$$L=\\int_{\\Omega} \\lVert |\\nabla\\Phi(x)| - 1 \\rVert\\mathrm{d}\\mathbf{x} + \\int_{\\Omega_0}\\lVert\\Phi(x)\\rVert + (1-\\nabla\\Phi(x) \\cdot n(x))\\mathrm{d}\\mathbf{x} + \\int_{\\Omega\\setminus\\Omega_0} \\Psi(\\Phi(x))\\mathrm{d}\\mathbf{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xo_7pXha1a8z"
   },
   "source": [
    "#### Define PyTorch Dataset\n",
    "\n",
    "* We use the Thai Statue from the 3D Stanford Model as our dataset (located at `/data/thai_statue.xyz`).\n",
    "* Visualization of xyz files is possible using MeshLab ([link](https://www.meshlab.net/)).\n",
    "* The dataset samples a specified number of points (`on_surface_points`) from the input point cloud and an equal number of points from the entire domain, returning the SDF and normal values for these points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 770,
     "status": "ok",
     "timestamp": 1692600184709,
     "user": {
      "displayName": "Seunguk Do",
      "userId": "05447261647661672061"
     },
     "user_tz": -540
    },
    "id": "U8aozp0KSgdf"
   },
   "outputs": [],
   "source": [
    "class PointCloud(Dataset):\n",
    "    def __init__(self, on_surface_points, keep_aspect_ratio=True):\n",
    "        super().__init__()\n",
    "\n",
    "        print(\"Loading point cloud\")\n",
    "        point_cloud = np.genfromtxt('/data/thai_statue.xyz')\n",
    "        print(\"Finished loading point cloud\")\n",
    "\n",
    "        coords = point_cloud[:, :3]\n",
    "        self.normals = point_cloud[:, 3:]\n",
    "\n",
    "        # Reshape point cloud such that it lies in bounding box of (-1, 1) (distorts geometry, but makes for high\n",
    "        # sample efficiency)\n",
    "        coords -= np.mean(coords, axis=0, keepdims=True)\n",
    "        if keep_aspect_ratio:\n",
    "            coord_max = np.amax(coords)\n",
    "            coord_min = np.amin(coords)\n",
    "        else:\n",
    "            coord_max = np.amax(coords, axis=0, keepdims=True)\n",
    "            coord_min = np.amin(coords, axis=0, keepdims=True)\n",
    "\n",
    "        self.coords = (coords - coord_min) / (coord_max - coord_min)\n",
    "        self.coords -= 0.5\n",
    "        self.coords *= 2.\n",
    "\n",
    "        self.on_surface_points = on_surface_points\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.coords.shape[0] // self.on_surface_points\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        point_cloud_size = self.coords.shape[0]\n",
    "\n",
    "        off_surface_samples = self.on_surface_points  # **2\n",
    "        total_samples = self.on_surface_points + off_surface_samples\n",
    "\n",
    "        # Random coords\n",
    "        rand_idcs = np.random.choice(point_cloud_size, size=self.on_surface_points)\n",
    "\n",
    "        on_surface_coords = self.coords[rand_idcs, :]\n",
    "        on_surface_normals = self.normals[rand_idcs, :]\n",
    "\n",
    "        off_surface_coords = np.random.uniform(-1, 1, size=(off_surface_samples, 3))\n",
    "        off_surface_normals = np.ones((off_surface_samples, 3)) * -1\n",
    "\n",
    "        sdf = np.zeros((total_samples, 1))  # on-surface = 0\n",
    "        sdf[self.on_surface_points:, :] = -1  # off-surface = -1\n",
    "\n",
    "        coords = np.concatenate((on_surface_coords, off_surface_coords), axis=0)\n",
    "        normals = np.concatenate((on_surface_normals, off_surface_normals), axis=0)\n",
    "\n",
    "        return {'coords': torch.from_numpy(coords).float()}, {'sdf': torch.from_numpy(sdf).float(),\n",
    "                                                              'normals': torch.from_numpy(normals).float()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Mesh Export Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gos7VN58eP0N"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import plyfile\n",
    "import skimage.measure\n",
    "\n",
    "\n",
    "def create_mesh(\n",
    "    decoder, filename, N=256, max_batch=64 ** 3, offset=None, scale=None\n",
    "):\n",
    "    start = time.time()\n",
    "    ply_filename = filename\n",
    "\n",
    "    decoder.eval()\n",
    "\n",
    "    # NOTE: the voxel_origin is actually the (bottom, left, down) corner, not the middle\n",
    "    voxel_origin = [-1, -1, -1]\n",
    "    voxel_size = 2.0 / (N - 1)\n",
    "\n",
    "    overall_index = torch.arange(0, N ** 3, 1, out=torch.LongTensor())\n",
    "    samples = torch.zeros(N ** 3, 4)\n",
    "\n",
    "    # transform first 3 columns\n",
    "    # to be the x, y, z index\n",
    "    samples[:, 2] = overall_index % N\n",
    "    samples[:, 1] = (overall_index.long() / N) % N\n",
    "    samples[:, 0] = ((overall_index.long() / N) / N) % N\n",
    "\n",
    "    # transform first 3 columns\n",
    "    # to be the x, y, z coordinate\n",
    "    samples[:, 0] = (samples[:, 0] * voxel_size) + voxel_origin[2]\n",
    "    samples[:, 1] = (samples[:, 1] * voxel_size) + voxel_origin[1]\n",
    "    samples[:, 2] = (samples[:, 2] * voxel_size) + voxel_origin[0]\n",
    "\n",
    "    num_samples = N ** 3\n",
    "\n",
    "    samples.requires_grad = False\n",
    "\n",
    "    head = 0\n",
    "\n",
    "    while head < num_samples:\n",
    "        print(head)\n",
    "        sample_subset = samples[head : min(head + max_batch, num_samples), 0:3].cuda()\n",
    "\n",
    "        samples[head : min(head + max_batch, num_samples), 3] = (\n",
    "            decoder(sample_subset)[0]\n",
    "            .squeeze()#.squeeze(1)\n",
    "            .detach()\n",
    "            .cpu()\n",
    "        )\n",
    "        head += max_batch\n",
    "\n",
    "    sdf_values = samples[:, 3]\n",
    "    sdf_values = sdf_values.reshape(N, N, N)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"sampling takes: %f\" % (end - start))\n",
    "\n",
    "    convert_sdf_samples_to_ply(\n",
    "        sdf_values.data.cpu(),\n",
    "        voxel_origin,\n",
    "        voxel_size,\n",
    "        ply_filename,\n",
    "        offset,\n",
    "        scale,\n",
    "    )\n",
    "\n",
    "\n",
    "def convert_sdf_samples_to_ply(\n",
    "    pytorch_3d_sdf_tensor,\n",
    "    voxel_grid_origin,\n",
    "    voxel_size,\n",
    "    ply_filename_out,\n",
    "    offset=None,\n",
    "    scale=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert sdf samples to .ply\n",
    "\n",
    "    :param pytorch_3d_sdf_tensor: a torch.FloatTensor of shape (n,n,n)\n",
    "    :voxel_grid_origin: a list of three floats: the bottom, left, down origin of the voxel grid\n",
    "    :voxel_size: float, the size of the voxels\n",
    "    :ply_filename_out: string, path of the filename to save to\n",
    "\n",
    "    This function adapted from: https://github.com/RobotLocomotion/spartan\n",
    "    \"\"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    numpy_3d_sdf_tensor = pytorch_3d_sdf_tensor.numpy()\n",
    "\n",
    "    verts, faces, normals, values = np.zeros((0, 3)), np.zeros((0, 3)), np.zeros((0, 3)), np.zeros(0)\n",
    "    verts, faces, normals, values = skimage.measure.marching_cubes(\n",
    "        numpy_3d_sdf_tensor, level=0.0, spacing=[voxel_size] * 3\n",
    "    )\n",
    "\n",
    "    # transform from voxel coordinates to camera coordinates\n",
    "    # note x and y are flipped in the output of marching_cubes\n",
    "    mesh_points = np.zeros_like(verts)\n",
    "    mesh_points[:, 0] = voxel_grid_origin[0] + verts[:, 0]\n",
    "    mesh_points[:, 1] = voxel_grid_origin[1] + verts[:, 1]\n",
    "    mesh_points[:, 2] = voxel_grid_origin[2] + verts[:, 2]\n",
    "\n",
    "    # apply additional offset and scale\n",
    "    if scale is not None:\n",
    "        mesh_points = mesh_points / scale\n",
    "    if offset is not None:\n",
    "        mesh_points = mesh_points - offset\n",
    "\n",
    "    # try writing to the ply file\n",
    "\n",
    "    num_verts = verts.shape[0]\n",
    "    num_faces = faces.shape[0]\n",
    "\n",
    "    verts_tuple = np.zeros((num_verts,), dtype=[(\"x\", \"f4\"), (\"y\", \"f4\"), (\"z\", \"f4\")])\n",
    "\n",
    "    for i in range(0, num_verts):\n",
    "        verts_tuple[i] = tuple(mesh_points[i, :])\n",
    "\n",
    "    faces_building = []\n",
    "    for i in range(0, num_faces):\n",
    "        faces_building.append(((faces[i, :].tolist(),)))\n",
    "    faces_tuple = np.array(faces_building, dtype=[(\"vertex_indices\", \"i4\", (3,))])\n",
    "\n",
    "    el_verts = plyfile.PlyElement.describe(verts_tuple, \"vertex\")\n",
    "    el_faces = plyfile.PlyElement.describe(faces_tuple, \"face\")\n",
    "\n",
    "    ply_data = plyfile.PlyData([el_verts, el_faces])\n",
    "    logging.debug(\"saving mesh to %s\" % (ply_filename_out))\n",
    "    ply_data.write(ply_filename_out)\n",
    "\n",
    "    logging.debug(\n",
    "        \"converting to ply format and writing to file took {} s\".format(\n",
    "            time.time() - start_time\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEFkrk62XC4H"
   },
   "source": [
    "#### Instantiate Dataset and SIREN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "error",
     "timestamp": 1692600185592,
     "user": {
      "displayName": "Seunguk Do",
      "userId": "05447261647661672061"
     },
     "user_tz": -540
    },
    "id": "vp0abYidWALn",
    "outputId": "fe568aae-d66d-468e-d5d4-1eec025f648f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thai_statue = PointCloud(250000)\n",
    "dataloader = DataLoader(thai_statue, batch_size=1, pin_memory=True, num_workers=0)\n",
    "\n",
    "sdf_siren = Siren(in_features=3, out_features=1, hidden_features=256,\n",
    "                  hidden_layers=3, outermost_linear=True)\n",
    "sdf_siren.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9qaeAP_1TN1"
   },
   "source": [
    "#### Define Loss Function and Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0JlLS-p1I6a"
   },
   "outputs": [],
   "source": [
    "def sdf_loss(pred_sdf, coords, gt_sdf, gt_normals):\n",
    "    '''\n",
    "       x: batch of input coordinates\n",
    "       y: usually the output of the trial_soln function\n",
    "       '''\n",
    "\n",
    "    _gradient = gradient(pred_sdf, coords)\n",
    "\n",
    "    # Wherever boundary_values is not equal to zero, we interpret it as a boundary constraint.\n",
    "    sdf_constraint = torch.where(gt_sdf != -1, pred_sdf, torch.zeros_like(pred_sdf))\n",
    "    inter_constraint = torch.where(gt_sdf != -1, torch.zeros_like(pred_sdf), torch.exp(-1e2 * torch.abs(pred_sdf)))\n",
    "    normal_constraint = torch.where(gt_sdf != -1, 1 - F.cosine_similarity(_gradient, gt_normals, dim=-1)[..., None],\n",
    "                                    torch.zeros_like(_gradient[..., :1]))\n",
    "    grad_constraint = torch.abs(_gradient.norm(dim=-1) - 1)\n",
    "    return {'sdf': torch.abs(sdf_constraint).mean() * 3e3,\n",
    "            'inter': inter_constraint.mean() * 1e2,\n",
    "            'normal_constraint': normal_constraint.mean() * 1e2,\n",
    "            'grad_constraint': grad_constraint.mean() * 5e1}\n",
    "\n",
    "\n",
    "def train(model, dataloader, log_dir, total_steps=2000, log_steps=250):\n",
    "    optim = torch.optim.Adam(lr=1e-4, params=model.parameters())\n",
    "    \n",
    "    model_input, ground_truth = next(iter(dataloader))\n",
    "    model_input, sdf_gt, normals_gt = model_input['coords'].cuda(), ground_truth['sdf'].cuda(), ground_truth['normals'].cuda()\n",
    "    \n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    with tqdm(total=total_steps) as pbar:\n",
    "        for step in range(total_steps):\n",
    "            sdf_pred, coords = model(model_input)\n",
    "            losses = sdf_loss(sdf_pred, coords, sdf_gt, normals_gt)\n",
    "            \n",
    "            train_loss = 0\n",
    "            log_message = \"Step %d, \" % step\n",
    "            for loss_name, loss in losses.items():\n",
    "                single_loss = loss.mean()\n",
    "                train_loss += single_loss\n",
    "                log_message += (\"%s %0.2f, \" % (loss_name, single_loss.item()))\n",
    "            pbar.set_description(log_message)\n",
    "\n",
    "            if not step % log_steps:\n",
    "                create_mesh(sdf_siren, log_dir / f\"{step}.ply\")\n",
    "        \n",
    "            optim.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBf30zlsDtsM"
   },
   "source": [
    "#### Exercise 4: Train ReLU Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohnoRjjEYs3X",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_dir = Path(\"./results/siren/pc_relu\")\n",
    "######## Implement from here ########\n",
    "\n",
    "####### End of Implementation #######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5: Train SIREN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = Path(\"./results/siren/pc_siren\")\n",
    "######## Implement from here ########\n",
    "\n",
    "####### End of Implementation #######"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/vsitzmann/siren/blob/master/explore_siren.ipynb",
     "timestamp": 1692450320919
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
